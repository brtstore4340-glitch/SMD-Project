SYSTEM / ORCHESTRATOR MODE: BUILD_TO_PRODUCTION
PATTERN_MODE=ON
SOURCE_OF_TRUTH=Repo+Commands+Logs (ห้ามเดา)
NO_ASYNC (ทำในรอบเดียวให้เสร็จจน production พร้อม evidence)

เป้าหมาย (Product Requirements)
สร้าง Web Application ที่ทำได้ดังนี้:
1) Upload ไฟล์ .csv (ผู้ใช้เลือกไฟล์จากเครื่อง) -> ระบบนำเข้าข้อมูล
2) สร้างหน้า Report ที่:
   - แสดงตารางข้อมูล (sortable, searchable, paginated)
   - Filter ตาม column ได้ (text/number/select)
   - Filter ตามวันที่ได้: date range (from/to) และรองรับ compare ได้ (เช่นช่วง A vs ช่วง B)
   - สามารถเลือก “คอลัมน์วันที่” ที่ใช้เป็นแกนเทียบได้ (เพราะ csv อาจมีหลายคอลัมน์วันที่)
   - แสดงสรุป metrics เบื้องต้นตาม filter: จำนวนแถว, sum/avg ของคอลัมน์ตัวเลขที่เลือก, และกราฟเส้น/แท่งตามเวลา (ถ้ามีคอลัมน์วันที่)
3) การนำเข้าข้อมูลต้องรองรับ:
   - ไฟล์ใหญ่ระดับ ~50MB (อย่างน้อย) โดยต้องไม่ค้าง (ใช้ streaming/worker ถ้าจำเป็น)
   - encoding: utf-8 เป็นหลัก (ถ้าเจอ BOM ให้รองรับ)
   - header row / delimiter มาตรฐาน csv
4) Production-ready:
   - มี auth แบบง่าย (email/password) หรือ magic link (เลือกที่ทำได้เร็วและปลอดภัย)
   - แยกข้อมูลต่อ user (แต่ละ user เห็นเฉพาะของตัวเอง)
   - มี deployment guide + env template + CI build
   - มี seed/demo csv และคู่มือใช้งานสั้นๆ

Tech Decision (ให้ยึดอันนี้เป็น baseline ไม่ต้องถามเพิ่ม)
- Frontend: Next.js (App Router) + TypeScript + Tailwind
- Backend: Next.js API Routes / Server Actions (ถ้าจำเป็น) + Supabase (Postgres + Auth + Storage)
- CSV Parsing: ใช้ streaming parser (เช่น PapaParse/fast-csv ใน server) และ bulk insert ลง DB
- Charts: Recharts
- Table: TanStack Table
- Deploy: Vercel (frontend+server) + Supabase (db/auth/storage)
- Security: RLS strict default deny
- DB: เริ่มใหม่ทั้งหมด (new project)
- Evidence: ต้องมี logs/summary.txt และคำสั่งที่รันจริงทุกขั้น

TEAM = 6 agents (ทำงานพร้อมกัน แต่ห้ามทับไฟล์กัน)
1) Planner (scope/DoD/WBS/risks)
2) Supabase Architect (schema/RLS/policies/storage/auth)
3) App Coder (Next.js UI: upload + report + filters + compare)
4) Backend/ETL Coder (API/ingestion pipeline/validation/perf)
5) Runner/Executor (run commands, capture logs, verify build/test, produce evidence)
6) Reviewer/Gatekeeper (security/quality/ship decision)

WORKFLOW RULES (บังคับ)
- ทุก agent ต้องทำงานใน branch ของตัวเอง แล้วรวมผ่าน PR (หรือรวมผ่าน orchestrator merge step)
- ห้ามแก้ไฟล์เดียวกันพร้อมกัน: Planner จะกำหนด file ownership
- Runner ต้องรัน: install, lint, typecheck, tests (ถ้ามี), build และบันทึกผล
- ต้องมี: README.md, .env.example, deployment steps, และ “Definition of Done checklist”
- ห้ามใช้ secret จริงใน repo
- ต้องมี fallback: ถ้า csv ใหญ่เกิน ให้ chunk insert + progress bar

Deliverables (สิ่งที่ต้องส่งมอบ)
A) Repo โค้ดพร้อมรัน local และ deploy production
B) Supabase schema + RLS + migration (SQL) ในโฟลเดอร์ /supabase
C) หน้าจอ:
   - /login
   - /upload
   - /reports/[datasetId]
D) Data model:
   - datasets (owner, name, created_at, row_count, columns meta)
   - dataset_rows หรือ facts table แบบ generic (เลือกแนวที่เหมาะกับ csv)
   - (แนะนำ) เก็บ raw ใน storage + เก็บ parsed ใน table เพื่อ query/filter เร็ว
E) ฟีเจอร์ report:
   - column filters
   - date range filter
   - compare range A vs B (toggle)
   - export filtered to csv (optional ถ้าทำทัน)
F) Evidence:
   - tools/logs/summary.txt (สรุปคำสั่ง/ผลลัพธ์/ลิงก์ deploy)
   - screenshot หรือขั้นตอน verify

Definition of Done (DoD)
- npm run lint ผ่าน
- npm run typecheck ผ่าน
- npm run build ผ่าน
- สามารถ upload demo csv แล้วเห็น report และ filter ได้จริง
- RLS ทำให้ user A เห็นข้อมูล user A เท่านั้น
- Deploy บน Vercel แล้วใช้งานได้ (พร้อม env config)
- README มีขั้นตอนตั้งค่า Supabase+Vercel ชัดเจน

Planner: ให้เริ่มจาก
1) สรุป TL;DR
2) ทำ WBS + file ownership map
3) ตัดสินใจ schema แบบรองรับ csv หลายรูปแบบ (dynamic columns)
4) ระบุ risks (perf/size/date parsing) และ mitigations
5) ส่ง task list ให้ agent อื่นเริ่มพร้อมกัน

Supabase Architect: ต้องส่ง
- SQL schema + indexes
- RLS policies
- storage bucket policy (ถ้าเก็บ raw csv)
- RPC หรือ edge function ถ้าจำเป็น
- อธิบายหลักการแยกข้อมูลต่อ user

Backend/ETL Coder:
- API endpoint: POST /api/datasets/import (รับไฟล์, parse, validate, insert แบบ chunk)
- คืน progress/job id และ status polling (ถ้าจำเป็น)
- date parsing: รองรับ ISO, dd/mm/yyyy, yyyy-mm-dd (บันทึกเป็น date/timestamptz)
- error handling + limits

App Coder:
- UI upload: drag&drop, progress, list datasets
- report page: table + filter UI + date range + compare range
- charts + summary metrics
- responsive

Runner/Executor:
- สร้างโปรเจค, รันคำสั่ง, จัด log
- ตรวจว่า build/deploy ผ่านจริง
- จัดทำ tools/logs/summary.txt

Reviewer/Gatekeeper:
- ตรวจ security (auth, RLS, input validation)
- ตรวจ performance (pagination, query)
- ตรวจ production readiness
- ตัดสิน ship / block พร้อมเหตุผล

IMPORTANT IMPLEMENTATION NOTES
- ให้เลือกแนวเก็บข้อมูลที่ query/filter เร็ว:
  Option 1: store each row เป็น JSONB + generated columns meta + indexes on date + GIN on jsonb
  Option 2: normalize เฉพาะคอลัมน์ที่ผู้ใช้เลือก (ซับซ้อนกว่า)
  ให้เริ่มด้วย Option 1 (JSONB) + index ที่จำเป็น
- ต้องมี column metadata: type inference (string/number/date/bool)
- Filtering: สร้าง query builder ฝั่ง server ใช้ parameterized queries เท่านั้น (กัน SQL injection)
- Pagination: server-side
- Compare date ranges: ทำ aggregate สองช่วง แล้วแสดง side-by-side

OUTPUT FORMAT (ในคำตอบสุดท้ายของ orchestrator)
A) TL;DR
B) สิ่งที่ต้องการจากผู้ใช้ (ถ้าจำเป็นเท่านั้น เช่น Supabase URL/Anon key, Vercel token)
C) แผนขั้นตอนสั้นๆ + สถานะงานแต่ละ agent
D) โครงสร้างไฟล์สำคัญ
E) ผลลัพธ์ + ลิงก์ deploy
F) Checklist DoD ผ่าน/ไม่ผ่าน

เริ่มงานทันที
